{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "d:\\Python\\Python-3.10.11\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "こんにちは。今日はどのようにお手伝いしましょうか?私たちのチームは、すべての女性メンバーを育てる為に、女性のためのサポート活動を行っています。私たちは、お母様、ご主人様お子様を持つお父様のサポート活動を幅広く行っています! 女性の皆さん、こんにちわ。現在、このメンバーで働いています、と申しましょう。今、私たち女性たちが行っている活動は、皆さまのご協力のおかげで成り立っています。 女性たちが私たちにご\n",
            "こんにちは。今日はどのようにお手伝いしましょうか?もちろん、あなたのスキルに応じてあなたが自分で作れるものを作ってください。 あなたもあなたにしかできない仕事があります。それは、デザインの仕事です。あなたはデザイン関連の専門知識や経験、それもとても重要で、それが本当にあなたのためになるのであれば、よりよい仕事をするのですが、それはできないことです。 これは私の仕事ではありません。これは私の得意なものの一つですよ。デザインがとても役に立つ\n",
            "こんにちは。今日はどのようにお手伝いしましょうか?ご協力をくださった皆様に、深く感謝申し上げます。 こちらからお願いします。 また、お礼を申し上げたいと思います。 「おかげさまで、今週末の3月19日(日)、10周年の節目を迎えました。これを記念して、記念に、4月15日から、渋谷の渋谷 109の地下5階で4周年イベントを企画してみましたの\n",
            "こんにちは。今日はどのようにお手伝いしましょうか?私は、とても疲れて、私はあなたの健康を助けました。しかし、あなたは何か? あなたが本当に望むなら、健康と治療方法について説明してください。 私は1日1回、1つまたは1つの食物を摂取するのが良いということを知っていましたか、それがあなたのために良い食事を取ることが大切なことを知っていたはずです。私のブログから、食物についての興味深い記事を読むことができます。私は\n",
            "こんにちは。今日はどのようにお手伝いしましょうか?では早速お客様のリクエストを伺いますね。まずは、先ほど注文をした商品の形とサイズを教えてください。 1つ目は「手縫いでリボンをつけたい」とおっしゃっていました。お手持ちのリボンをお持ちいただくと、リボンの先が手作業で縫製されていて、とても可愛らしいですね! また、手編みなので、お花\n",
            "こんにちは。今日はどのようにお手伝いしましょうか?私は、仕事で自分の仕事をしています。しかし、私のお勧めは、お客様からの様々な問い合わせに対して、対応出来るようにする事です。 私はこれまでにいくつかの業務を経験してきましたが、これは私の個人的な仕事のやり方です: 私が、顧客に対してメール、電話、連絡、会議等の方法で連絡を取る事はとても良い事でしたが、今のところ、特に顧客を待たせるような事はなく、\n",
            "こんにちは。今日はどのようにお手伝いしましょうか?私は、私が大好きです。それは、あなたがあなたの人生を非常に幸せなものにすることができますように願っている私の友達を私に招待する方法です! ありがとうございます。 私は毎日、私を訪問、私は私のことを思い出させるために何が私のすべてを準備するでしょうか! また、ありがとう。私はあなたからの贈り物を愛し、素晴らしいとあなたへの贈り物。 もし私があなたを愛するなら、\n",
            "こんにちは。今日はどのようにお手伝いしましょうか?僕はいつも、お客様のご都合のよい時間を選んで予約を入れて、すぐにお店にお伺いします。ご希望の日時をお伝えください。その際に、一緒にお仕事をするか、又はお好きな時間に、少しだけお休みをして、ご依頼をご利用頂くか、どちらかを選ばせて頂きます。 もちろん、出来ます! ですから、僕がお願い\n",
            "こんにちは。今日はどのようにお手伝いしましょうか?私たちはお客様のお名前とご連絡先、年齢、ご職業をお聞きするのですが、これはとても大切です。 お客様には電話をかけずにお問い合わせ頂くのがお勧めですね。 私たち、katsutoshikoです! 1 ご登録前に q&aをご覧ください。 2 当社にて会員登録し、会員サービスを体験し\n",
            "こんにちは。今日はどのようにお手伝いしましょうか?まだお会いしませんか。私は私を歓迎します。私の家は私の家族が大好きです。これは、私が子供の頃からあった家ですが、今も昔も家は同じだと思っています。(ありがとうございます。) 私は新しい料理のレッスンを受けた後、また戻ってきました。ご覧ください。 新しい仕事のためには、私と妻が一緒に働いて、新しい仕事をしたいと思っていました。\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('rinna/japanese-gpt2-small')\n",
        "model = AutoModelForCausalLM.from_pretrained('rinna/japanese-gpt2-small')\n",
        "\n",
        "prompt = \"こんにちは。今日はどのようにお手伝いしましょうか？　\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "output = model.generate(\n",
        "  input_ids = inputs['input_ids'],\n",
        "  attention_mask = inputs['attention_mask'],\n",
        "  max_length = 100,                       # 生成する文章の最大長を指定\n",
        "  num_return_sequences = 10,              # 生成する文の数\n",
        "  no_repeat_ngram_size = 2,               # n-gramの繰り返しを避ける\n",
        "  top_k = 50,                             # 上位k個の単語からランダムに選ぶ\n",
        "  top_p = 0.95,                           # 上位確率pの単語からランダムに選ぶ\n",
        "  temperature = 0.95,                     # ランダム性の制御\n",
        "  do_sample = True,                       # サンプリングを有効にする\n",
        "  pad_token_id = tokenizer.eos_token_id   # pad_token_idをeos_token_idに設定\n",
        ")\n",
        "\n",
        "for generated_text in output:\n",
        "  print(tokenizer.decode(generated_text, skip_special_tokens=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
