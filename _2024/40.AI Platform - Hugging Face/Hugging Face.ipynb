{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 日本語感情分析のためのパイプラインを作成\n",
    "classifier = pipeline('sentiment-analysis', model='kit-nlp/bert-base-japanese-sentiment-irony')\n",
    "\n",
    "# 分析するテキスト\n",
    "texts = [\n",
    "  \"この製品が大好きです！とても使いやすいです。\",\n",
    "  \"これは最悪の体験でした。\",\n",
    "  \"この件に関しては中立的です。\",\n",
    "  \"まあまあですね。特に良くも悪くもないです。\"\n",
    "]\n",
    "\n",
    "# 感情分析を実行\n",
    "results = classifier(texts)\n",
    "\n",
    "# 結果を表示\n",
    "for text, result in zip(texts, results):\n",
    "  print(f\"テキスト: {text}\")\n",
    "  print(f\"感情: {result['label']}, 信頼度: {result['score']:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 日本語感情分析のためのパイプラインを作成\n",
    "classifier = pipeline('sentiment-analysis', model='kit-nlp/bert-base-japanese-sentiment-irony')\n",
    "\n",
    "# 分析するテキスト\n",
    "texts = [\n",
    "  \"この製品が大好きです！とても使いやすいです。\",\n",
    "  \"これは最悪の体験でした。\",\n",
    "  \"この件に関しては中立的です。\",\n",
    "  \"まあまあですね。特に良くも悪くもないです。\"\n",
    "]\n",
    "\n",
    "# 感情分析を実行\n",
    "results = classifier(texts)\n",
    "\n",
    "# 結果を表示\n",
    "for text, result in zip(texts, results):\n",
    "  print(f\"テキスト: {text}\")\n",
    "  print(f\"感情: {result['label']}, 信頼度: {result['score']:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('text-classification', model='cl-tohoku/bert-base-japanese')\n",
    "text = \"今日はとても良い天気です。\"\n",
    "result = classifier(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# NERパイプラインの作成\n",
    "ner = pipeline('ner', model='asahi417/tner-xlm-roberta-base-ontonotes5')\n",
    "\n",
    "# 入力テキスト\n",
    "text = \"東京都は日本の首都であり、多くの観光地があります。首相の岸田文雄氏も住んでいます。\"\n",
    "\n",
    "# NERの実行\n",
    "result = ner(text)\n",
    "\n",
    "# 結果の表示\n",
    "for entity in result:\n",
    "  print(f\"Entity: {entity['word']}, Type: {entity['entity']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 質問応答パイプラインの作成\n",
    "qa = pipeline('question-answering', model='deepset/xlm-roberta-large-squad2')\n",
    "\n",
    "# コンテキスト（文章）\n",
    "context = \"\"\"\n",
    "日本は東アジアに位置する島国で、豊かな自然と文化を持つ国です。国土は本州、北海道、九州、四国という4つの主要な島と、多数の小さな島々から成り立っています。\n",
    "総面積は約377,975平方キロメートルで、国土の約70%が山地です。\n",
    "富士山は日本の本州に位置する活火山であり、日本で最も高い山です。標高は3776メートルで、毎年多くの登山者や観光客が訪れます。\n",
    "日本の文化は、伝統的なものと現代的なものが共存しています。茶道、華道、書道などの伝統芸術や、能、歌舞伎といった伝統芸能は、今も多くの人々に愛されています。\n",
    "一方で、アニメ、マンガ、ゲームなどのポップカルチャーも世界中で人気を集めています。\n",
    "日本料理は、その美味しさと健康への配慮から、世界中で高く評価されています。寿司、天ぷら、うどん、ラーメンなど、多彩な料理が楽しめます。特に、和食は2013年にユネスコ無形文化遺産に登録されました。\n",
    "京都府やや奈良県には多くの寺院があり、外国人観光客からも人気です。特に金閣寺や清水寺、東大寺などが有名です。\n",
    "\"\"\"\n",
    "\n",
    "# 質問\n",
    "question = \"日本で最も高い山は何ですか？\"\n",
    "\n",
    "# 質問応答の実行\n",
    "results = qa(question=question, context=context, top_k=5)\n",
    "\n",
    "# 最もスコアが高い回答を選択\n",
    "best_answer = max(results, key=lambda x: x['score'])\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Best Answer: {best_answer['answer']}\")\n",
    "print(f\"Score: {best_answer['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 翻訳パイプラインの作成\n",
    "translator = pipeline('translation', model='Helsinki-NLP/opus-mt-ja-en')\n",
    "\n",
    "# 入力テキスト\n",
    "text = \"\"\"\n",
    "日本は東アジアに位置する島国で、豊かな自然と文化を持つ国です。国土は本州、北海道、九州、四国という4つの主要な島と、多数の小さな島々から成り立っています。\n",
    "総面積は約377,975平方キロメートルで、国土の約70%が山地です。\n",
    "富士山は日本の本州に位置する活火山であり、日本で最も高い山です。標高は3776メートルで、毎年多くの登山者や観光客が訪れます。\n",
    "日本の文化は、伝統的なものと現代的なものが共存しています。茶道、華道、書道などの伝統芸術や、能、歌舞伎といった伝統芸能は、今も多くの人々に愛されています。\n",
    "一方で、アニメ、マンガ、ゲームなどのポップカルチャーも世界中で人気を集めています。\n",
    "日本料理は、その美味しさと健康への配慮から、世界中で高く評価されています。寿司、天ぷら、うどん、ラーメンなど、多彩な料理が楽しめます。特に、和食は2013年にユネスコ無形文化遺産に登録されました。\n",
    "京都府やや奈良県には多くの寺院があり、外国人観光客からも人気です。特に金閣寺や清水寺、東大寺などが有名です。\n",
    "\"\"\"\n",
    "\n",
    "# 翻訳の実行\n",
    "result = translator(text)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Translation: {result[0]['translation_text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 要約パイプラインの作成\n",
    "summarizer = pipeline('summarization', model='sonoisa/t5-base-japanese', tokenizer='sonoisa/t5-base-japanese')\n",
    "\n",
    "# 入力テキスト\n",
    "text = \"\"\"\n",
    "日本は東アジアに位置する島国で、豊かな自然と文化を持つ国です。国土は本州、北海道、九州、四国という4つの主要な島と、多数の小さな島々から成り立っています。\n",
    "総面積は約377,975平方キロメートルで、国土の約70%が山地です。\n",
    "富士山は日本の本州に位置する活火山であり、日本で最も高い山です。標高は3776メートルで、毎年多くの登山者や観光客が訪れます。\n",
    "日本の文化は、伝統的なものと現代的なものが共存しています。茶道、華道、書道などの伝統芸術や、能、歌舞伎といった伝統芸能は、今も多くの人々に愛されています。\n",
    "一方で、アニメ、マンガ、ゲームなどのポップカルチャーも世界中で人気を集めています。\n",
    "日本料理は、その美味しさと健康への配慮から、世界中で高く評価されています。寿司、天ぷら、うどん、ラーメンなど、多彩な料理が楽しめます。特に、和食は2013年にユネスコ無形文化遺産に登録されました。\n",
    "京都府やや奈良県には多くの寺院があり、外国人観光客からも人気です。特に金閣寺や清水寺、東大寺などが有名です。\n",
    "\"\"\"\n",
    "\n",
    "# 要約の実行\n",
    "result = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Summary: {result[0]['summary_text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# テキスト生成パイプラインの作成\n",
    "generator = pipeline('text-generation', model='rinna/japanese-gpt2-medium', tokenizer='rinna/japanese-gpt2-medium')\n",
    "\n",
    "# 入力テキスト\n",
    "text = \"昔々あるところに、\"\n",
    "\n",
    "# テキスト生成の実行\n",
    "result = generator(text, max_length=100, num_return_sequences=1)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Generated Text: {result[0]['generated_text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Fill-Maskパイプラインの作成\n",
    "fill_mask = pipeline('fill-mask', model='cl-tohoku/bert-base-japanese', tokenizer='cl-tohoku/bert-base-japanese')\n",
    "\n",
    "# 入力テキスト\n",
    "text = \"私は[MASK]が好きです。\"\n",
    "\n",
    "# Fill-Maskの実行\n",
    "results = fill_mask(text)\n",
    "\n",
    "# 結果の表示\n",
    "for result in results:\n",
    "  print(f\"Token: {result['token_str']}, Score: {result['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Zero-Shot Classificationパイプラインの作成\n",
    "classifier = pipeline('zero-shot-classification', model='joeddav/xlm-roberta-large-xnli')\n",
    "\n",
    "# 入力テキスト\n",
    "text = \"今日はとても良い天気です。\"\n",
    "\n",
    "# ラベルの候補\n",
    "candidate_labels = [\"天気\", \"感情\", \"ニュース\"]\n",
    "\n",
    "# Zero-Shot Classificationの実行\n",
    "result = classifier(text, candidate_labels)\n",
    "\n",
    "# 結果の表示\n",
    "for label, score in zip(result['labels'], result['scores']):\n",
    "  print(f\"Label: {label}, Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "# テキスト生成パイプラインの作成\n",
    "generator = pipeline('text-generation', model='rinna/japanese-gpt2-medium', tokenizer='rinna/japanese-gpt2-medium')\n",
    "\n",
    "# 入力テキスト\n",
    "text = \"昔々あるところに、\"\n",
    "\n",
    "# テキスト生成の実行\n",
    "generated_text = generator(text, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "\n",
    "# 生成されたテキストの表示\n",
    "print(f\"Generated Text: {generated_text}\")\n",
    "\n",
    "# gTTSを使用して音声合成\n",
    "tts = gTTS(text=generated_text, lang='ja')\n",
    "tts.save(\"output.mp3\")\n",
    "\n",
    "# 保存された音声ファイルを再生\n",
    "os.system(\"start output.mp3\")  # Windowsの場合\n",
    "# os.system(\"afplay output.mp3\")  # macOSの場合\n",
    "# os.system(\"mpg321 output.mp3\")  # Linuxの場合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoFeatureExtractor, BeitForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# モデルと特徴抽出器の読み込み\n",
    "model_name = 'microsoft/beit-base-patch16-224-pt22k-ft22k'\n",
    "model = BeitForImageClassification.from_pretrained(model_name)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# 画像の読み込み\n",
    "url = \"https://www.anicom-sompo.co.jp/inu/wp-content/uploads/2020/12/samoedo.jpg\"  # ここに画像のURLを指定\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# 画像の前処理\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# 推論の実行\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "  logits = outputs.logits\n",
    "\n",
    "# 最も確信度の高いラベルを取得\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "labels = model.config.id2label\n",
    "predicted_label = labels[predicted_class_idx]\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Predicted label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "from PIL import Image, ImageDraw\n",
    "import requests\n",
    "\n",
    "# モデルと特徴抽出器の読み込み\n",
    "model_name = 'facebook/detr-resnet-50'\n",
    "model = DetrForObjectDetection.from_pretrained(model_name)\n",
    "feature_extractor = DetrImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# 画像の読み込み\n",
    "url = \"https://images.unsplash.com/photo-1567306226416-28f0efdc88ce\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# 画像の前処理\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# 推論の実行\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "\n",
    "# 推論結果の処理\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = feature_extractor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]\n",
    "\n",
    "# 検出結果を画像に描画\n",
    "draw = ImageDraw.Draw(image)\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "  if score > 0.9:  # 確信度が0.9以上の検出結果のみ表示\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    draw.rectangle(box, outline=\"red\", width=3)\n",
    "    draw.text((box[0], box[1]), f\"{model.config.id2label[label.item()]}: {round(score.item(), 3)}\", fill=\"red\")\n",
    "\n",
    "# 結果の表示\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DetrImageProcessor, DetrForSegmentation\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# モデルと特徴抽出器の読み込み\n",
    "model_name = 'facebook/detr-resnet-50-panoptic'\n",
    "model = DetrForSegmentation.from_pretrained(model_name)\n",
    "feature_extractor = DetrImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# 画像の読み込み\n",
    "url = \"https://images.unsplash.com/photo-1567306226416-28f0efdc88ce\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# 画像の前処理\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# 推論の実行\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "\n",
    "# 推論結果の処理\n",
    "processed_outputs = feature_extractor.post_process_panoptic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "\n",
    "# セグメンテーション結果の取得\n",
    "segments_info = processed_outputs[\"segments_info\"]\n",
    "segmentation = processed_outputs[\"segmentation\"].numpy()\n",
    "\n",
    "# セグメンテーション結果を画像に描画\n",
    "draw = ImageDraw.Draw(image)\n",
    "unique_labels = np.unique(segmentation)\n",
    "\n",
    "for segment in segments_info:\n",
    "  if segment['score'] > 0.85:  # スコアが0.85以上のセグメントのみ表示\n",
    "    mask = segmentation == segment['id']\n",
    "    bbox = np.array(np.nonzero(mask))\n",
    "    ymin, xmin = bbox.min(axis=1)\n",
    "    ymax, xmax = bbox.max(axis=1)\n",
    "    draw.rectangle([xmin, ymin, xmax, ymax], outline=\"red\", width=2)\n",
    "    draw.text((xmin, ymin), f\"{model.config.id2label[segment['label_id']]}: {segment['score']:.2f}\", fill=\"red\")\n",
    "\n",
    "# 結果の表示\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DetrFeatureExtractor, DetrModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# モデルと特徴抽出器の読み込み\n",
    "model_name = 'facebook/detr-resnet-50'\n",
    "model = DetrModel.from_pretrained(model_name)\n",
    "feature_extractor = DetrFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# 画像の読み込み\n",
    "url = \"https://images.unsplash.com/photo-1567306226416-28f0efdc88ce\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# 画像の前処理\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# 推論の実行\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "\n",
    "# 特徴量の抽出\n",
    "features = outputs.last_hidden_state\n",
    "\n",
    "# 特徴量の表示\n",
    "print(\"特徴量の形状:\", features.shape)\n",
    "print(\"特徴量:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# テキスト生成パイプラインの作成\n",
    "generator = pipeline('text-generation', model='rinna/japanese-gpt2-medium', tokenizer='rinna/japanese-gpt2-medium')\n",
    "\n",
    "# 入力テキスト\n",
    "text = \"昔々あるところに、\"\n",
    "\n",
    "# テキスト生成の実行\n",
    "result = generator(text, max_length=100, num_return_sequences=1)\n",
    "\n",
    "# 生成されたテキストの取得\n",
    "generated_text = result[0]['generated_text']\n",
    "print(f\"Generated Text: {generated_text}\")\n",
    "\n",
    "# gTTSを使用して音声合成\n",
    "tts = gTTS(text=generated_text, lang='ja')\n",
    "tts.save(\"output.mp3\")\n",
    "\n",
    "# 音声ファイルを再生\n",
    "def play_audio(filename):\n",
    "  data, fs = sf.read(filename, dtype='float32')\n",
    "  sd.play(data, fs)\n",
    "  status = sd.wait()  # 再生終了まで待機\n",
    "\n",
    "play_audio(\"output.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "\n",
    "# モデルとトークナイザーの読み込み\n",
    "model_name = 'rinna/japanese-gpt2-medium'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# データセットの準備\n",
    "train_file_path = \"train_data.txt\"    # トレーニングデータのファイルパス\n",
    "val_file_path = \"val_data.txt\"        # バリデーションデータのファイルパス\n",
    "\n",
    "# データセットの読み込み\n",
    "train_dataset = load_dataset('text', data_files=train_file_path, split='train')\n",
    "val_dataset = load_dataset('text', data_files=val_file_path, split='train')\n",
    "\n",
    "# トークナイズ関数の定義\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# データセットのトークナイズ\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# データコラテーターの作成\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "  tokenizer=tokenizer,\n",
    "  mlm=False,\n",
    ")\n",
    "\n",
    "# 絶対パスでの出力ディレクトリの指定\n",
    "output_dir = os.path.abspath('./results')\n",
    "logging_dir = os.path.abspath('./logs')\n",
    "\n",
    "# トレーニングパラメータの設定\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=output_dir,\n",
    "  overwrite_output_dir=True,\n",
    "  num_train_epochs=3,\n",
    "  per_device_train_batch_size=4,\n",
    "  per_device_eval_batch_size=4,\n",
    "  warmup_steps=500,\n",
    "  weight_decay=0.01,\n",
    "  logging_dir=logging_dir,\n",
    "  logging_steps=10,\n",
    ")\n",
    "\n",
    "# トレーナーの作成\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset=train_dataset,\n",
    "  eval_dataset=val_dataset,\n",
    "  data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# トレーニングの実行\n",
    "trainer.train()\n",
    "\n",
    "# ファインチューニング済みモデルの保存\n",
    "model_save_path = os.path.abspath('./fine_tuned_gpt2')\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "#------------------------------------------------------#\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# ファインチューニング済みモデルとトークナイザーの読み込み\n",
    "generator = pipeline('text-generation', model=model_save_path, tokenizer=model_save_path)\n",
    "\n",
    "# 入力テキスト\n",
    "text = \"昔々あるところに、\"\n",
    "\n",
    "# テキスト生成の実行\n",
    "result = generator(text, max_length=100, num_return_sequences=1)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Generated Text: {result[0]['generated_text']}\")\n",
    "\n",
    "# gTTSを使用して音声合成\n",
    "from gtts import gTTS\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "\n",
    "tts = gTTS(text=result[0]['generated_text'], lang='ja')\n",
    "tts.save(\"output.mp3\")\n",
    "\n",
    "# 音声ファイルを再生\n",
    "def play_audio(filename):\n",
    "    data, fs = sf.read(filename, dtype='float32')\n",
    "    sd.play(data, fs)\n",
    "    status = sd.wait()  # 再生終了まで待機\n",
    "\n",
    "play_audio(\"output.mp3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
