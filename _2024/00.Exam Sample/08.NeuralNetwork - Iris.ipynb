{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GDV0BejdeOE9"},"outputs":[],"source":["import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0LwXu37YeOFA","outputId":"a4d586a6-2283-4373-a7e6-c4467fe3dcfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["(120, 4)\n","(120, 3)\n"]}],"source":["data_iris = load_iris()                         # アヤメのデータセットの読み込み\n","\n","# print(data_iris.feature_names)                # 説明変数の表示\n","# print(data_iris.target_names)                 # 目的変数の表示\n","# print(data_iris['DESCR'])                     # 変数の説明の表示\n","\n","scaler = StandardScaler()\n","\n","x_train, x_test, y_train, y_test = train_test_split(data_iris.data, data_iris.target, test_size=0.2, random_state=0)\n","\n","x_train_reshaped = x_train.reshape(-1, 4)           # 本来は必要なし。元々 1 次元ベクトル\n","x_train_normalized = scaler.fit_transform(x_train_reshaped)\n","y_train_categorized = np.eye(3)[y_train]\n","\n","x_test_reshaped = x_test.reshape(-1, 4)             # 本来は必要なし。元々 1 次元ベクトル\n","x_test_normalized = scaler.fit_transform(x_test_reshaped)\n","y_test_categorized = np.eye(3)[y_test]\n","\n","print(x_train_reshaped.shape)\n","print(y_train_categorized.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_Ltc2UoeOFC","outputId":"a71c1c5b-84f0-4d21-ea72-5fd52819039f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.1362, Accuracy: 0.8500\n","Epoch 2, Loss: 0.1162, Accuracy: 0.8667\n","Epoch 3, Loss: 0.1036, Accuracy: 0.8750\n","Epoch 4, Loss: 0.0940, Accuracy: 0.8750\n","Epoch 5, Loss: 0.0864, Accuracy: 0.8917\n","Epoch 6, Loss: 0.0801, Accuracy: 0.9167\n","Epoch 7, Loss: 0.0747, Accuracy: 0.9333\n","Epoch 8, Loss: 0.0701, Accuracy: 0.9417\n","Epoch 9, Loss: 0.0659, Accuracy: 0.9417\n","Epoch 10, Loss: 0.0622, Accuracy: 0.9417\n","Epoch 11, Loss: 0.0586, Accuracy: 0.9583\n","Epoch 12, Loss: 0.0555, Accuracy: 0.9583\n","Epoch 13, Loss: 0.0526, Accuracy: 0.9583\n","Epoch 14, Loss: 0.0501, Accuracy: 0.9583\n","Epoch 15, Loss: 0.0478, Accuracy: 0.9583\n","Epoch 16, Loss: 0.0457, Accuracy: 0.9583\n","Epoch 17, Loss: 0.0439, Accuracy: 0.9583\n","Epoch 18, Loss: 0.0423, Accuracy: 0.9583\n","Epoch 19, Loss: 0.0408, Accuracy: 0.9583\n","Epoch 20, Loss: 0.0394, Accuracy: 0.9583\n","Epoch 21, Loss: 0.0381, Accuracy: 0.9583\n","Epoch 22, Loss: 0.0370, Accuracy: 0.9583\n","Epoch 23, Loss: 0.0359, Accuracy: 0.9583\n","Epoch 24, Loss: 0.0349, Accuracy: 0.9583\n","Epoch 25, Loss: 0.0339, Accuracy: 0.9583\n","Epoch 26, Loss: 0.0331, Accuracy: 0.9667\n","Epoch 27, Loss: 0.0323, Accuracy: 0.9667\n","Epoch 28, Loss: 0.0316, Accuracy: 0.9667\n","Epoch 29, Loss: 0.0309, Accuracy: 0.9750\n","Epoch 30, Loss: 0.0302, Accuracy: 0.9750\n","Epoch 31, Loss: 0.0296, Accuracy: 0.9750\n","Epoch 32, Loss: 0.0291, Accuracy: 0.9750\n","Epoch 33, Loss: 0.0286, Accuracy: 0.9750\n","Epoch 34, Loss: 0.0281, Accuracy: 0.9750\n","Epoch 35, Loss: 0.0276, Accuracy: 0.9750\n","Epoch 36, Loss: 0.0272, Accuracy: 0.9750\n","Epoch 37, Loss: 0.0268, Accuracy: 0.9750\n","Epoch 38, Loss: 0.0264, Accuracy: 0.9750\n","Epoch 39, Loss: 0.0261, Accuracy: 0.9750\n","Epoch 40, Loss: 0.0258, Accuracy: 0.9750\n","Epoch 41, Loss: 0.0254, Accuracy: 0.9750\n","Epoch 42, Loss: 0.0251, Accuracy: 0.9750\n","Epoch 43, Loss: 0.0249, Accuracy: 0.9750\n","Epoch 44, Loss: 0.0246, Accuracy: 0.9750\n","Epoch 45, Loss: 0.0243, Accuracy: 0.9750\n","Epoch 46, Loss: 0.0241, Accuracy: 0.9750\n","Epoch 47, Loss: 0.0239, Accuracy: 0.9750\n","Epoch 48, Loss: 0.0236, Accuracy: 0.9750\n","Epoch 49, Loss: 0.0234, Accuracy: 0.9750\n","Epoch 50, Loss: 0.0232, Accuracy: 0.9750\n","Epoch 51, Loss: 0.0230, Accuracy: 0.9750\n","Epoch 52, Loss: 0.0228, Accuracy: 0.9750\n","Epoch 53, Loss: 0.0226, Accuracy: 0.9750\n","Epoch 54, Loss: 0.0225, Accuracy: 0.9750\n","Epoch 55, Loss: 0.0223, Accuracy: 0.9750\n","Epoch 56, Loss: 0.0222, Accuracy: 0.9750\n","Epoch 57, Loss: 0.0220, Accuracy: 0.9750\n","Epoch 58, Loss: 0.0218, Accuracy: 0.9750\n","Epoch 59, Loss: 0.0217, Accuracy: 0.9750\n","Epoch 60, Loss: 0.0216, Accuracy: 0.9750\n","Epoch 61, Loss: 0.0214, Accuracy: 0.9750\n","Epoch 62, Loss: 0.0213, Accuracy: 0.9750\n","Epoch 63, Loss: 0.0212, Accuracy: 0.9750\n","Epoch 64, Loss: 0.0211, Accuracy: 0.9750\n","Epoch 65, Loss: 0.0209, Accuracy: 0.9750\n","Epoch 66, Loss: 0.0208, Accuracy: 0.9750\n","Epoch 67, Loss: 0.0207, Accuracy: 0.9750\n","Epoch 68, Loss: 0.0206, Accuracy: 0.9750\n","Epoch 69, Loss: 0.0205, Accuracy: 0.9750\n","Epoch 70, Loss: 0.0204, Accuracy: 0.9750\n","Epoch 71, Loss: 0.0203, Accuracy: 0.9750\n","Epoch 72, Loss: 0.0202, Accuracy: 0.9750\n","Epoch 73, Loss: 0.0201, Accuracy: 0.9750\n","Epoch 74, Loss: 0.0201, Accuracy: 0.9750\n","Epoch 75, Loss: 0.0200, Accuracy: 0.9750\n","Epoch 76, Loss: 0.0199, Accuracy: 0.9750\n","Epoch 77, Loss: 0.0198, Accuracy: 0.9750\n","Epoch 78, Loss: 0.0197, Accuracy: 0.9750\n","Epoch 79, Loss: 0.0196, Accuracy: 0.9750\n","Epoch 80, Loss: 0.0196, Accuracy: 0.9750\n","Epoch 81, Loss: 0.0195, Accuracy: 0.9750\n","Epoch 82, Loss: 0.0194, Accuracy: 0.9750\n","Epoch 83, Loss: 0.0194, Accuracy: 0.9750\n","Epoch 84, Loss: 0.0193, Accuracy: 0.9750\n","Epoch 85, Loss: 0.0192, Accuracy: 0.9750\n","Epoch 86, Loss: 0.0192, Accuracy: 0.9750\n","Epoch 87, Loss: 0.0191, Accuracy: 0.9750\n","Epoch 88, Loss: 0.0191, Accuracy: 0.9750\n","Epoch 89, Loss: 0.0190, Accuracy: 0.9750\n","Epoch 90, Loss: 0.0189, Accuracy: 0.9750\n","Epoch 91, Loss: 0.0189, Accuracy: 0.9750\n","Epoch 92, Loss: 0.0188, Accuracy: 0.9750\n","Epoch 93, Loss: 0.0188, Accuracy: 0.9750\n","Epoch 94, Loss: 0.0187, Accuracy: 0.9750\n","Epoch 95, Loss: 0.0187, Accuracy: 0.9750\n","Epoch 96, Loss: 0.0186, Accuracy: 0.9750\n","Epoch 97, Loss: 0.0186, Accuracy: 0.9750\n","Epoch 98, Loss: 0.0185, Accuracy: 0.9750\n","Epoch 99, Loss: 0.0185, Accuracy: 0.9750\n","Epoch 100, Loss: 0.0184, Accuracy: 0.9750\n","Accuracy Score: 0.9667\n","[2 1 0 2 0 2 0 1 1 1]\n","[2 1 0 2 0 2 0 1 1 1]\n"]}],"source":["#------------------------------------------------------------------------------\n","# Neural Network\n","#------------------------------------------------------------------------------\n","class NeuralNetwork:\n","\n","  def __init__(self, input_size, hidden_size, output_size):\n","\n","    self.hidden_weight = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)          # He 初期化\n","    self.hidden_bias = np.zeros((1, hidden_size))\n","\n","    self.output_weight = np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / hidden_size)        # He 初期化\n","    self.output_bias = np.zeros((1, output_size))\n","\n","  def func_relu(self, x):\n","    y = np.maximum(0, x)\n","    return y\n","\n","  def func_relu_deriv(self, x):\n","    y = np.where(x > 0, 1, 0)\n","    return y\n","\n","  def func_softmax(self, x):\n","    exp_x = np.exp(x - np.max(x))\n","    y = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n","    return y\n","\n","  def func_forward(self, x_data):\n","\n","    ans = np.dot(x_data, self.hidden_weight) + self.hidden_bias\n","    hidden_data = self.func_relu(ans)\n","\n","    ans = np.dot(hidden_data, self.output_weight) + self.output_bias\n","    output_data = self.func_softmax(ans)\n","\n","    return hidden_data, output_data\n","\n","  def func_backward(self, x_data, y_data, hidden_data, output_data):\n","\n","    learning_rate = 0.1\n","\n","    output_loss = output_data - y_data\n","    output_weight = hidden_data.T.dot(output_loss)\n","    output_bias = np.sum(output_loss, axis=0)\n","\n","    hidden_loss = output_loss.dot(self.output_weight.T) * self.func_relu_deriv(hidden_data)\n","    hidden_weight = x_data.T.dot(hidden_loss)\n","    hidden_bias = np.sum(hidden_loss, axis=0)\n","\n","    self.output_weight -= learning_rate * output_weight / len(x_data)\n","    self.output_bias -= learning_rate * output_bias / len(x_data)\n","\n","    self.hidden_weight -= learning_rate * hidden_weight / len(x_data)\n","    self.hidden_bias -= learning_rate * hidden_bias / len(x_data)\n","\n","  def func_train(self, x_data, y_data):\n","\n","    batch_size = 10\n","    epochs = 100\n","\n","    for e in range(epochs):\n","      for i in range(0, len(x_data), batch_size):\n","        x_batch = x_data[i: i + batch_size]\n","        y_batch = y_data[i: i + batch_size]\n","        hidden_data, output_data = self.func_forward(x_batch)\n","        self.func_backward(x_batch, y_batch, hidden_data, output_data)\n","\n","      _, output_data = self.func_forward(x_data)\n","      acc_score = np.mean(np.argmax(output_data, axis=1) == np.argmax(y_data, axis=1))\n","      loss_value = np.mean(-y_data * np.log(output_data))\n","      print(f'Epoch {e + 1}, Loss: {loss_value:.4f}, Accuracy: {acc_score:.4f}')\n","\n","  def func_predict(self, x):\n","    _, output_data = self.func_forward(x)\n","    return np.argmax(output_data, axis=1)\n","\n","#------------------------------------------------------------------------------\n","# Main\n","#------------------------------------------------------------------------------\n","neural_network = NeuralNetwork(4, 10, 3)\n","neural_network.func_train(x_train_normalized, y_train_categorized)\n","\n","y_pred = neural_network.func_predict(x_test_normalized)\n","acc_score = np.mean(y_pred == y_test)\n","\n","print(f'Accuracy Score: {acc_score:.4f}')\n","\n","print(y_test[:10])\n","print(y_pred[:10])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}