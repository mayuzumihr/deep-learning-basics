{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import MeCab\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['宮沢 賢治', '北原 白秋', '芥川 竜之介', 'カフカ フランツ', 'ポー エドガー・アラン']\n",
      "[['aobikaru_tenkonohateni.txt', 'aoyagikyoyuo_okuru.txt', 'akita_kaido.txt', 'akutaukaberu_asanomizu.txt', 'akegata.txt', 'asanitsuiteno.txt', 'amenimo_makezu.txt', 'arito_kinoko.txt', 'aru_nogakuseino_nisshi.txt', 'igirisu_kaigan.txt'], ['02aino_shishuno_hajimeni.txt', 'asakusa_aika.txt', 'unasaka.txt', 'otsukisama_ikutsu.txt', 'omoide.txt', 'kaihyoto_kumo.txt', 'kage.txt', 'kazami.txt', 'kansono_aki.txt', 'kansono_toki.txt'], ['aidokushono_insho.txt', 'aki.txt', 'akutagawa_ryunosuke_kashu.txt', 'agunino_kami.txt', 'agunino_kami.txt', 'akuma.txt', 'asakusa_koen.txt', 'anikino_yona_kokoromochi.txt', 'anokorono_jibun.txt', 'ababababa.txt'], ['ieno_arujitoshite_kininarukoto.txt', 'kachono_shinpai.txt', 'kafu.txt', 'koteino_shisha.txt', 'saishono_kuno.txt', 'shokeino_hanashi.txt', 'shiro.txt', 'shinpan.txt', 'danjiki_geinin.txt', 'tsumi_kutsu_kibo_oyobi.txt'], ['usher_keno_fukumetsu.txt', 'asshakeno_hokai.txt', 'william_wilson.txt', 'uzushio.txt', 'otoshianato_furiko.txt', 'kuroneko.txt', 'gunshuno_hito.txt', 'koganemushi.txt', 'shimeshi_awase.txt', 'jusanji.txt']]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 作品の収集\n",
    "# ---------------------------------------------------------\n",
    "def collect_books(author_url, books_count):\n",
    "\n",
    "  author_name = None\n",
    "  book_files = []\n",
    "\n",
    "  ### 作者のページから、作家名を収集 ###\n",
    "  response = requests.get(author_url)\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "  for tr in soup.find_all('tr'):\n",
    "    header_td = tr.find('td', class_='header')\n",
    "    if header_td and '作家名' in header_td.get_text():\n",
    "      next_td = header_td.find_next_sibling('td')\n",
    "      if next_td:\n",
    "        font_tag = next_td.find('font', size='+2')\n",
    "        if font_tag:\n",
    "          author_name = font_tag.get_text()\n",
    "          break\n",
    "\n",
    "  ### 作者のページから、書籍の URL を収集 ###\n",
    "  book_urls = []\n",
    "  \n",
    "  for ol in soup.find_all('ol'):\n",
    "    for li in soup.find_all('li'):\n",
    "      a_tag = li.find('a', href=True)\n",
    "      if a_tag:\n",
    "        href = a_tag['href']\n",
    "        if (href[0:3] == '../'):\n",
    "          book_urls.append('https://www.aozora.gr.jp/' + href.split('../')[1])\n",
    "\n",
    "  ### 書籍のページから zip ファイルの URL を収集 ###\n",
    "  file_urls = []\n",
    "  file_index = 0\n",
    "\n",
    "  for url in book_urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    for td in soup.find_all('td'):\n",
    "      if ((\"テキストファイル(ルビあり)\" in td.get_text()) or \n",
    "          (\"テキストファイル(ルビなし)\" in td.get_text())):\n",
    "        a_tag = td.find_next('a', href=True)\n",
    "        if a_tag:\n",
    "          href = a_tag['href']\n",
    "          break\n",
    "\n",
    "    url = re.match(r'(https://www\\.aozora\\.gr\\.jp/cards/\\d+/)', url)\n",
    "\n",
    "    if (file_index < books_count):\n",
    "     if (href[0:3] == './'):\n",
    "        file_urls.append(url.group(1) + href.split('./')[1])\n",
    "        file_index = file_index + 1\n",
    "    else:\n",
    "      break\n",
    "\n",
    "  ### zip ファイルをダウンロードして保存 ###\n",
    "  zip_dir = 'zip_' + author_name\n",
    "  os.makedirs(zip_dir, exist_ok=True)\n",
    "\n",
    "  for url in file_urls:\n",
    "    response = requests.get(url)\n",
    "    file_path = os.path.join(zip_dir, url.split('/')[-1])\n",
    "\n",
    "    with open(file_path, 'wb') as file:\n",
    "      file.write(response.content)\n",
    "\n",
    "  ### zip ファイルを解凍してテキストファイルのみを保存 ###\n",
    "  txt_dir = 'txt_' + author_name\n",
    "  os.makedirs(txt_dir, exist_ok=True)\n",
    "\n",
    "  for file in os.listdir(zip_dir):\n",
    "    if file.endswith('.zip'):\n",
    "      file_path = os.path.join(zip_dir, file)\n",
    "\n",
    "      with zipfile.ZipFile(file_path, 'r') as file:\n",
    "        for file_info in file.infolist():\n",
    "          if file_info.filename.endswith('.txt'):\n",
    "            file.extract(file_info, txt_dir)\n",
    "            book_files.append(file_info.filename)\n",
    "\n",
    "  return author_name, book_files\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# メイン（書籍の最初の 10 件をダウンロード）\n",
    "# ---------------------------------------------------------\n",
    "url_list = [\n",
    "  'https://www.aozora.gr.jp/index_pages/person81.html',       # 宮沢 賢治\n",
    "  'https://www.aozora.gr.jp/index_pages/person106.html',      # 北原 白秋\n",
    "  'https://www.aozora.gr.jp/index_pages/person879.html',      # 芥川 竜之介  \n",
    "  'https://www.aozora.gr.jp/index_pages/person1235.html',     # フランツ・カフカ  \n",
    "  'https://www.aozora.gr.jp/index_pages/person94.html'        # エドガー・アラン・ポー  \n",
    "]\n",
    "\n",
    "author_list = []\n",
    "file_list = []\n",
    "\n",
    "for list in url_list:\n",
    "  author, book_files = collect_books(list, 10)                # 書籍を 10 件取集\n",
    "  author_list.append(author)                                  # 作者を保存\n",
    "  file_list.append(book_files)                                # ファイル名を保存\n",
    "\n",
    "print(author_list)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# データの作成\n",
    "# ---------------------------------------------------------\n",
    "def create_data(author_name, txt_files):\n",
    "  txt_dir = 'txt_' + author_name\n",
    "  book_list = []\n",
    "  content_list = []\n",
    "\n",
    "  # ファイルの読み込みとコンテンツの保存\n",
    "  for file_name in txt_files:\n",
    "    file_path = os.path.join(txt_dir, file_name)\n",
    "    with open(file_path, 'r', encoding='shift-jis') as file:\n",
    "      book_list.append(file.readline().strip())                   # 書籍名を取得\n",
    "      content_list.append(tokenize(sanitize(file.read())))        # 不要な部分を削除したコンテンツのトークンを取得\n",
    "\n",
    "  return book_list, content_list\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# コンテンツの不要な部分を削除\n",
    "# ---------------------------------------------------------\n",
    "def sanitize(text):\n",
    "  operations = [\n",
    "    lambda text: re.split(r'\\-{5,}', text)[2],\n",
    "    lambda text: re.split(r'底本：', text)[0],\n",
    "    lambda text: re.sub(r'《.+?》', '', text),\n",
    "    lambda text: re.sub(r'［＃.+?］', '', text),\n",
    "    lambda text: text.strip()\n",
    "  ]\n",
    "\n",
    "  for operation in operations:\n",
    "    try:\n",
    "      text = operation(text)\n",
    "    except Exception as e:\n",
    "      pass\n",
    "\n",
    "  return text\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 形態素解析\n",
    "# ---------------------------------------------------------\n",
    "def tokenize(text):\n",
    "  tagger = MeCab.Tagger(\"\")\n",
    "  node = tagger.parseToNode(text)\n",
    "  tokens = []\n",
    "\n",
    "  while node is not None:\n",
    "    part = node.feature.split(\",\")[0]\n",
    "    if part in [\"名詞\", \"動詞\", \"形容詞\"]:\n",
    "      tokens.append(node.surface)\n",
    "    node = node.next\n",
    "\n",
    "  return tokens\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# メイン\n",
    "# ---------------------------------------------------------\n",
    "tagged_data = []\n",
    "\n",
    "# データの作成\n",
    "for i in range(len(author_list)):\n",
    "  book_list, content_list = create_data(author_list[i], file_list[i])\n",
    "  for j in range(len(book_list)):\n",
    "    tag = f'{author_list[i]}：{book_list[j]}'\n",
    "    tagged_data.append(TaggedDocument(words=content_list[j], tags=[tag]))\n",
    "\n",
    "# Doc2Vecモデルの作成\n",
    "model = Doc2Vec(vector_size=50, min_count=2, epochs=50)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "宮沢 賢治：〔青びかる天弧のはてに〕：0.942288339138031\n",
      "宮沢 賢治：〔あくたうかべる朝の水〕：0.799717128276825\n",
      "宮沢 賢治：青柳教諭を送る：0.7855112552642822\n",
      "北原 白秋：影：0.7746310234069824\n",
      "宮沢 賢治：〔雨ニモマケズ〕：0.7709150910377502\n",
      "北原 白秋：風見：0.7199495434761047\n",
      "北原 白秋：浅草哀歌：0.6917543411254883\n",
      "芥川 竜之介：芥川龍之介歌集：0.6599308252334595\n",
      "北原 白秋：お月さまいくつ：0.6357375383377075\n",
      "芥川 竜之介：愛読書の印象：0.5989206433296204\n"
     ]
    }
   ],
   "source": [
    "new_text = '青びかる天弧のはてに、きらゝかに町はうかびて、六月のたつきのみちは、いまやはた尽きはてにけり。いさゝかの書籍とセロを、思ふまゝ'\n",
    "new_text_tokens = tokenize(new_text)\n",
    "new_vector = model.infer_vector(new_text_tokens)\n",
    "\n",
    "similar_docs = model.dv.most_similar([new_vector], topn=10)\n",
    "\n",
    "for label, similarity in similar_docs:\n",
    "  print(f\"{label}：{similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "宮沢 賢治：〔青びかる天弧のはてに〕：0.9306557178497314\n",
      "宮沢 賢治：青柳教諭を送る：0.7792282104492188\n",
      "宮沢 賢治：〔あくたうかべる朝の水〕：0.7784576416015625\n",
      "北原 白秋：影：0.7782227396965027\n",
      "宮沢 賢治：〔雨ニモマケズ〕：0.7529142498970032\n",
      "北原 白秋：風見：0.7118601202964783\n",
      "北原 白秋：浅草哀歌：0.6950361132621765\n",
      "芥川 竜之介：芥川龍之介歌集：0.6396581530570984\n",
      "芥川 竜之介：愛読書の印象：0.6129152774810791\n",
      "北原 白秋：お月さまいくつ：0.6119818091392517\n"
     ]
    }
   ],
   "source": [
    "# 新しいテキストのトークン化\n",
    "new_text = '青びかる天弧のはてに、きらゝかに町はうかびて、六月のたつきのみちは、いまやはた尽きはてにけり。いさゝかの書籍とセロを、思ふまゝ'\n",
    "new_text_tokens = tokenize(new_text)\n",
    "new_vector = model.infer_vector(new_text_tokens)\n",
    "\n",
    "# すべてのドキュメントベクトルを取得\n",
    "doc_vectors = np.array([model.dv[i] for i in range(len(model.dv))])\n",
    "doc_labels = [model.dv.index_to_key[i] for i in range(len(model.dv))]\n",
    "\n",
    "# コサイン類似度の計算\n",
    "new_vector = new_vector.reshape(1, -1)\n",
    "cosine_similarities = cosine_similarity(new_vector, doc_vectors).flatten()\n",
    "similar_indices = cosine_similarities.argsort()[-10:][::-1]\n",
    "\n",
    "# 結果の表示\n",
    "for idx in similar_indices:\n",
    "  print(f\"{doc_labels[idx]}：{cosine_similarities[idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
