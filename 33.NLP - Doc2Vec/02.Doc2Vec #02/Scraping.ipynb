{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6d31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import requests\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee9daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================\n",
    "# 作品の収集\n",
    "#=======================================================\n",
    "def collect_books(author_url, books_count):\n",
    "\n",
    "  author_name = None\n",
    "  book_files = []\n",
    "\n",
    "#=======================================================\n",
    "# 作者のページから、作家名を収集\n",
    "#=======================================================\n",
    "  response = requests.get(author_url)\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "  for tr in soup.find_all('tr'):\n",
    "    header_td = tr.find('td', class_='header')\n",
    "    if header_td and '作家名' in header_td.get_text():\n",
    "      next_td = header_td.find_next_sibling('td')\n",
    "      if next_td:\n",
    "        font_tag = next_td.find('font', size='+2')\n",
    "        if font_tag:\n",
    "          author_name = font_tag.get_text()\n",
    "          break\n",
    "\n",
    "#=======================================================\n",
    "# 作者のページから、書籍の URL を収集\n",
    "#=======================================================\n",
    "  book_urls = []\n",
    "  \n",
    "  for ol in soup.find_all('ol'):\n",
    "    for li in soup.find_all('li'):\n",
    "      a_tag = li.find('a', href=True)\n",
    "      if a_tag:\n",
    "        href = a_tag['href']\n",
    "        if (href[0:3] == '../'):\n",
    "          book_urls.append('https://www.aozora.gr.jp/' + href.split('../')[1])\n",
    "\n",
    "#=======================================================\n",
    "# 書籍のページから zip ファイルの URL を収集\n",
    "#=======================================================\n",
    "  file_urls = []\n",
    "  file_index = 0\n",
    "\n",
    "  for url in book_urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    for td in soup.find_all('td'):\n",
    "      if ((\"テキストファイル(ルビあり)\" in td.get_text()) or \n",
    "          (\"テキストファイル(ルビなし)\" in td.get_text())):\n",
    "        a_tag = td.find_next('a', href=True)\n",
    "        if a_tag:\n",
    "          href = a_tag['href']\n",
    "          break\n",
    "\n",
    "    url = re.match(r'(https://www\\.aozora\\.gr\\.jp/cards/\\d+/)', url)\n",
    "\n",
    "    if (file_index < books_count):\n",
    "      file_urls.append(url.group(1) + href.split('./')[1])\n",
    "      file_index = file_index + 1\n",
    "    else:\n",
    "      break\n",
    "\n",
    "#=======================================================\n",
    "# zip ファイルをダウンロードして保存\n",
    "#=======================================================\n",
    "  zip_dir = 'zip_' + author_name\n",
    "  os.makedirs(zip_dir, exist_ok=True)\n",
    "\n",
    "  for url in file_urls:\n",
    "    response = requests.get(url)\n",
    "    file_path = os.path.join(zip_dir, url.split('/')[-1])\n",
    "\n",
    "    with open(file_path, 'wb') as file:\n",
    "      file.write(response.content)\n",
    "\n",
    "#=======================================================\n",
    "# zip ファイルを解凍してテキストファイルのみを保存\n",
    "#=======================================================\n",
    "  txt_dir = 'txt_' + author_name\n",
    "  os.makedirs(txt_dir, exist_ok=True)\n",
    "\n",
    "  for file in os.listdir(zip_dir):\n",
    "    if file.endswith('.zip'):\n",
    "      file_path = os.path.join(zip_dir, file)\n",
    "\n",
    "      with zipfile.ZipFile(file_path, 'r') as file:\n",
    "        for file_info in file.infolist():\n",
    "          if file_info.filename.endswith('.txt'):\n",
    "            file.extract(file_info, txt_dir)\n",
    "            book_files.append(file_info.filename)\n",
    "\n",
    "  return author_name, book_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b0b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['宮沢 賢治', '北原 白秋', '芥川 竜之介', 'カフカ フランツ', 'ポー エドガー・アラン']\n",
      "[['aobikaru_tenkonohateni.txt', 'aoyagikyoyuo_okuru.txt', 'akita_kaido.txt', 'akutaukaberu_asanomizu.txt', 'akegata.txt', 'asanitsuiteno.txt', 'amenimo_makezu.txt', 'arito_kinoko.txt', 'aru_nogakuseino_nisshi.txt', 'igirisu_kaigan.txt'], ['02aino_shishuno_hajimeni.txt', 'asakusa_aika.txt', 'unasaka.txt', 'otsukisama_ikutsu.txt', 'omoide.txt', 'kaihyoto_kumo.txt', 'kage.txt', 'kazami.txt', 'kansono_aki.txt', 'kansono_toki.txt'], ['aidokushono_insho.txt', 'aki.txt', 'akutagawa_ryunosuke_kashu.txt', 'agunino_kami.txt', 'agunino_kami.txt', 'akuma.txt', 'asakusa_koen.txt', 'anikino_yona_kokoromochi.txt', 'anokorono_jibun.txt', 'ababababa.txt'], ['ieno_arujitoshite_kininarukoto.txt', 'kachono_shinpai.txt', 'kafu.txt', 'koteino_shisha.txt', 'saishono_kuno.txt', 'shokeino_hanashi.txt', 'shiro.txt', 'shinpan.txt', 'danjiki_geinin.txt', 'tsumi_kutsu_kibo_oyobi.txt'], ['usher_keno_fukumetsu.txt', 'asshakeno_hokai.txt', 'william_wilson.txt', 'uzushio.txt', 'otoshianato_furiko.txt', 'kuroneko.txt', 'gunshuno_hito.txt', 'koganemushi.txt', 'shimeshi_awase.txt', 'jusanji.txt']]\n"
     ]
    }
   ],
   "source": [
    "#=======================================================\n",
    "# メイン（書籍の最初の 10 件をダウンロード）\n",
    "#=======================================================\n",
    "url_list = [\n",
    "  'https://www.aozora.gr.jp/index_pages/person81.html',       # 宮沢 賢治\n",
    "  'https://www.aozora.gr.jp/index_pages/person106.html',      # 北原 白秋\n",
    "  'https://www.aozora.gr.jp/index_pages/person879.html',      # 芥川 竜之介  \n",
    "  'https://www.aozora.gr.jp/index_pages/person1235.html',     # フランツ・カフカ  \n",
    "  'https://www.aozora.gr.jp/index_pages/person94.html'        # エドガー・アラン・ポー  \n",
    "]\n",
    "\n",
    "author_list = []\n",
    "file_list = []\n",
    "\n",
    "for list in url_list:\n",
    "  author, book_files = collect_books(list, 10)                # 書籍を 10 件取集\n",
    "  author_list.append(author)                                  # 作者を保存\n",
    "  file_list.append(book_files)                                # ファイル名を保存\n",
    "\n",
    "print(author_list)\n",
    "print(file_list)\n",
    "\n",
    "with open(\"book_data.pkl\", \"wb\") as f:          # wb = write-binary\n",
    "  pickle.dump(\n",
    "    {\"author_list\": author_list, \"file_list\": file_list},\n",
    "    f\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
